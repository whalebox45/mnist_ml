{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53739819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "USE_MPS = True\n",
    "\n",
    "# device\n",
    "if USE_MPS:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"üçé Using Apple MPS GPU\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"üíª Using CPU\")\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"üî• Using NVIDIA CUDA GPU\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"üíª Using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_ds = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "test_ds = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48979751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(x[i][0], cmap=\"gray\")\n",
    "    plt.title(str(y[i].item()))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5471f4",
   "metadata": {},
   "source": [
    "## CNN Ë®ìÁ∑¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1786e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = CNN().to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848287f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ce970",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "\n",
    "EPOCHES = 15\n",
    "\n",
    "for epoch in range(EPOCHES):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg = total_loss / len(train_loader)\n",
    "    train_losses.append(avg)\n",
    "    print(f\"Epoch {epoch+1} | loss = {avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bab8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "\n",
    "acc = correct / len(test_ds)\n",
    "print(\"Test accuracy =\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d40a0a",
   "metadata": {},
   "source": [
    "## ÂÑ≤Â≠òÊ®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âª∫Ë≠∞Ë∑ØÂæëÂæåÁ∂¥‰ΩøÁî® .pth Êàñ .pt\n",
    "model_path = \"mnist_cnn.pth\"\n",
    "\n",
    "# ÂÑ≤Â≠òÊ®°ÂûãÊ¨äÈáç (state_dict)\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Ê®°ÂûãÂ∑≤ÂÑ≤Â≠òËá≥ {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb14a26d",
   "metadata": {},
   "source": [
    "## ËÆÄÂèñÊ®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38183b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = False\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    # 1. ÂàùÂßãÂåñÊ®°ÂûãÁµêÊßã (ÂøÖÈ†àËàáË®ìÁ∑¥ÊôÇÂÆöÁæ©ÁöÑ CNN È°û‰∏ÄËá¥)\n",
    "    loaded_model = CNN() \n",
    "\n",
    "    # 2. ËºâÂÖ•Ê¨äÈáçÊ™îÊ°à\n",
    "    model_path = \"mnist_cnn.pth\"\n",
    "    state_dict = torch.load(model_path, map_location=device) # ËÄÉÊÖÆÂà∞ÂèØËÉΩÂú®‰∏çÂêåË®≠ÂÇôÈñìËºâÂÖ•\n",
    "\n",
    "    # 3. Â∞áÊ¨äÈáçÂ•óÁî®Âà∞Ê®°Âûã‰∏≠\n",
    "    loaded_model.load_state_dict(state_dict)\n",
    "\n",
    "    # 4. Â∞áÊ®°ÂûãÁßªËá≥Ê≠£Á¢∫ÁöÑË®≠ÂÇô (CPU Êàñ MPS/GPU) ‰∏¶Ë®≠ÁÇ∫Ë©ï‰º∞Ê®°Âºè\n",
    "    # Â¶ÇÊûúÊúâ‰ΩøÁî® MPS/GPUÔºåË®òÂæóÊää model.to(device) Ë®≠ÂÆöÊàêÊ≠£Á¢∫ÁöÑË®≠ÂÇô\n",
    "\n",
    "    loaded_model.to(device)\n",
    "    loaded_model.eval()\n",
    "\n",
    "    print(\"Ê®°ÂûãËºâÂÖ•ÊàêÂäüÔºåÂèØ‰ª•Áõ¥Êé•ÈÄ≤Ë°åÈ†êÊ∏¨„ÄÇ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3174992",
   "metadata": {},
   "source": [
    "## User Ëº∏ÂÖ•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3705e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "img_path = \"5.1.png\"   # Êîæ‰Ω†Ëá™Â∑±ÁöÑÂúñ\n",
    "\n",
    "img = Image.open(img_path).convert(\"L\")  # ËΩâÁÅ∞Èöé\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56261ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â¶ÇÊûúÂúñÊòØÁôΩÂ∫ïÈªëÂ≠óÔºåË®òÂæóÂèçËΩâ\n",
    "img = F.invert(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02617982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array(img)\n",
    "\n",
    "# Ëá™ÂãïÂà§Êñ∑ÂâçÊôØÈ°èËâ≤\n",
    "if arr.mean() > 127:   # ÁôΩÂ∫ïÈªëÂ≠ó\n",
    "    mask = arr < 200\n",
    "else:                  # ÈªëÂ∫ïÁôΩÂ≠ó\n",
    "    mask = arr > 50\n",
    "\n",
    "ys, xs = np.where(mask)\n",
    "\n",
    "top, bottom = ys.min(), ys.max()\n",
    "left, right = xs.min(), xs.max()\n",
    "\n",
    "img_crop = img.crop((left, top, right, bottom))\n",
    "plt.imshow(img_crop, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e8df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_CROP = False\n",
    "\n",
    "import torchvision.transforms as T\n",
    "transform = T.Compose([\n",
    "    T.Resize((28,28)),      # ‚ö†Ô∏è ÈóúÈçµ\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "if IS_CROP:\n",
    "    x = transform(img_crop)\n",
    "else:\n",
    "    x = transform(img)\n",
    "x = x.unsqueeze(0).to(device)\n",
    "\n",
    "plt.imshow(x[0][0].cpu(), cmap=\"gray\")\n",
    "plt.title(\"Final 28x28\")\n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "    pred = out.argmax(dim=1).item()\n",
    "\n",
    "print(\"Ê®°ÂûãÁåúÁöÑÊòØ:\", pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
